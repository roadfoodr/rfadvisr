import streamlit as st

import os
import yaml
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
import datetime
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import Document
import re

# Constants
EDITION = '10th'

# Set up Streamlit page configuration - MUST be the first Streamlit command
st.set_page_config(
    page_title=f"Roadfood {EDITION} Edition Search",
    page_icon="üçΩÔ∏è",
    layout="wide"
)

# OPENAI API SETUP
os.environ['OPENAI_API_KEY'] = yaml.safe_load(open('credentials.yml'))['openai']
MODEL_EMBEDDING = 'text-embedding-ada-002'
LLM_MODEL = 'gpt-3.5-turbo'

# Initialize embedding function
@st.cache_resource
def get_embedding_function():
    return OpenAIEmbeddings(
        model=MODEL_EMBEDDING,
    )

# Initialize LLM
@st.cache_resource
def get_llm():
    return ChatOpenAI(model=LLM_MODEL, temperature=0.7)

# Load the existing Chroma database
@st.cache_resource
def get_vectorstore():
    embedding_function = get_embedding_function()
    persist_directory = f"./data/chroma_rf{EDITION}"
    return Chroma(
        embedding_function=embedding_function,
        persist_directory=persist_directory
    )

# Get cached resources
embedding_function = get_embedding_function()
llm = get_llm()
vectorstore = get_vectorstore()

def post_process_summary(summary_text, search_results):
    """
    Post-process the summary to bold all restaurant names and add hyperlinks to their first occurrence.
    
    Args:
        summary_text: The text of the summary generated by the LLM
        search_results: The search results containing restaurant metadata
    
    Returns:
        Processed summary text with formatting applied
    """
    # Extract restaurant names and URLs from search results
    restaurants = []
    for doc in search_results:
        # Extract metadata if available
        metadata = getattr(doc, 'metadata', {})
        restaurant_name = metadata.get('Restaurant', '')
        url = metadata.get('URL', '')
        
        # Only process if we have a restaurant name
        if restaurant_name:
            restaurants.append({
                'name': restaurant_name,
                'url': url
            })
    
    # Track first occurrences
    first_occurrence = {r['name']: True for r in restaurants}
    
    # Sort restaurant names by length (descending) to avoid partial replacements
    # (e.g., replace "Joe's Diner" before "Joe")
    restaurants.sort(key=lambda x: len(x['name']), reverse=True)
    
    # Process each restaurant name
    for restaurant in restaurants:
        name = restaurant['name']
        url = restaurant['url']
        
        # Skip empty names
        if not name.strip():
            continue
        
        # Create regex pattern to match whole words/phrases only
        # This avoids replacing parts of other words
        # Use word boundaries \b for single-word restaurant names
        if len(name.split()) == 1:
            # For single words, use word boundaries
            pattern = r'(?<!\*\*)\b' + re.escape(name) + r'\b(?!\*\*)'
        else:
            # For phrases, use the existing pattern
            pattern = r'(?<!\*\*)' + re.escape(name) + r'(?!\*\*)'
        
        # Check if the name appears in the text
        if re.search(pattern, summary_text, re.IGNORECASE):
            # For the first occurrence, add hyperlink (if URL exists) and bold
            if first_occurrence[name]:
                if url:
                    # Add https:// prefix if missing
                    if not url.startswith('http'):
                        url = f"https://{url}"
                    # Replace with hyperlinked and bolded version
                    replacement = f"[**{name}**]({url})"
                else:
                    # Just bold if no URL
                    replacement = f"**{name}**"
                
                # Replace only the first occurrence (case insensitive)
                summary_text = re.sub(pattern, replacement, summary_text, count=1, flags=re.IGNORECASE)
                first_occurrence[name] = False
                
                # Bold all subsequent occurrences
                # Use the same pattern for consistency
                summary_text = re.sub(pattern, f"**{name}**", summary_text, flags=re.IGNORECASE)
            
    return summary_text

def load_prompt_template(prompt_type="basic"):
    """Load the prompt template from file
    
    Args:
        prompt_type: Type of prompt to load ("basic" or "advanced")
    
    Returns:
        The prompt template text or None if there was an error
    """
    filename = f"prompts/{prompt_type}_summary_prompt.txt"
    try:
        with open(filename, "r") as f:
            return f.read()
    except Exception as e:
        st.error(f"Error reading prompt template {filename}: {str(e)}")
        return None

def reload_prompt_template():
    """Clear the cache to reload the prompt template"""
    # Clear the cache to force reload of prompt
    st.cache_data.clear()
    st.success("Prompt templates reloaded!")

def generate_summary(query, full_content, search_results, prompt_type="basic"):
    """Generate a summary article from the search results using an LLM
    
    Args:
        query: The search query
        full_content: The full content of the search results
        search_results: The search results objects
        prompt_type: Type of prompt to use ("basic" or "advanced")
        
    Returns:
        The generated summary
    """
    # Read the prompt template from file
    prompt_text = load_prompt_template(prompt_type)
    
    # Fallback to hardcoded prompt if file can't be read
    if not prompt_text:
        prompt_text = """
        You are a food writer creating a summary article based on search results for "{query}".
        
        Here are the details of restaurants found in the search:
        {full_content}
                
        Format your response with markdown.
        """
    
    # Create the prompt for the LLM
    prompt_template = ChatPromptTemplate.from_template(prompt_text)
    
    # Generate the summary
    chain = prompt_template | llm
    response = chain.invoke({"query": query, "full_content": full_content})
    
    # Post-process the summary to format restaurant names
    processed_summary = post_process_summary(response.content, search_results)
    
    return processed_summary

@st.cache_data
def perform_search(query, num_results):
    """Perform the vector search and return results"""
    if not query.strip():
        return []
    
    try:
        results = vectorstore.similarity_search(
            query=query,
            k=num_results
        )
        return results
    except Exception as e:
        st.error(f"Error during search: {str(e)}")
        return []

def save_results_to_file(query, content):
    """Save results to a file and return the filename"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"data/search_results_{timestamp}.txt"
    os.makedirs(os.path.dirname(filename), exist_ok=True)  # Ensure directory exists
    
    with open(filename, "w") as f:
        f.write(f"Search query: {query}\n\n")
        f.write(content)
    
    return filename

# Create Streamlit interface
st.title(f"Roadfood {EDITION} Edition Restaurant Search")
st.markdown("Search for restaurants based on your preferences, cuisine, location, etc.")

# Example queries outside the form (these don't trigger re-renders)
example_queries = [
    "Where is the best BBQ?",
    "Unique seafood restaurants on the East Coast",
    "Famous diners in New Jersey",
    "Where can I find good pie?",
    "Historic restaurants with great burgers"
]

# Store the selected example in session state so we can use it in the form
if 'selected_example' not in st.session_state:
    st.session_state.selected_example = ""

def update_example():
    if st.session_state.example_selector:
        st.session_state.selected_example = st.session_state.example_selector

# Example selector outside the form
st.sidebar.header("Example Searches")
st.sidebar.selectbox(
    "Try an example search:",
    [""] + example_queries,
    key="example_selector",
    on_change=update_example
)

# Add a button to reload the prompt template
st.sidebar.header("Developer Options")
if st.sidebar.button("Reload Prompt Template"):
    reload_prompt_template()

# Create a form for all search inputs
with st.sidebar:
    with st.form(key="search_form"):
        st.header("Search Options")
        
        # Search parameters
        query_input = st.text_area(
            "What are you looking for?",
            value=st.session_state.selected_example,
            placeholder="e.g., 'best BBQ in Texas' or 'unique seafood restaurants'"
        )
        
        num_results = st.slider(
            "Number of results",
            min_value=1,
            max_value=10,
            value=4,
            step=1
        )
        
        generate_article_checkbox = st.checkbox("Generate summary article", value=True)
        
        # Only show this option if generate_article_checkbox is checked
        show_both_summaries = False
        if generate_article_checkbox:
            show_both_summaries = st.checkbox("Show both basic and advanced summaries", value=True)
        
        save_checkbox = st.checkbox("Save results to file", value=False)
        
        # Form submit button
        search_submitted = st.form_submit_button("Search")

# Main content area - only process when form is submitted
if search_submitted:
    if not query_input.strip():
        st.warning("Please enter a search query.")
    else:
        with st.spinner("Searching for restaurants..."):
            # Perform the search
            search_results = perform_search(query_input, num_results)
            
            if search_results:
                # Process and display results based on user preferences
                if generate_article_checkbox:
                    # Extract full content for summarization
                    full_content = "\n\n".join([doc.page_content for doc in search_results])
                    
                    # Generate basic summary
                    with st.spinner("Generating basic summary..."):
                        basic_summary = generate_summary(query_input, full_content, search_results, prompt_type="basic")
                    
                    # Display basic summary
                    if show_both_summaries:
                        st.subheader("Basic Summary")
                        st.markdown(basic_summary)
                        
                        # Generate and display advanced summary
                        with st.spinner("Generating advanced summary..."):
                            advanced_summary = generate_summary(query_input, full_content, search_results, prompt_type="advanced")
                        
                        st.subheader("Advanced Summary")
                        st.markdown(advanced_summary)
                        
                        # Save both summaries if requested
                        if save_checkbox:
                            combined_content = f"BASIC SUMMARY:\n\n{basic_summary}\n\n{'='*50}\n\nADVANCED SUMMARY:\n\n{advanced_summary}"
                            filename = save_results_to_file(query_input, combined_content)
                            st.markdown(f"\n\n*Results saved to {filename}*")
                    else:
                        # Just display the basic summary without a subheader
                        st.markdown(basic_summary)
                        
                        # Save only basic summary if requested
                        if save_checkbox:
                            filename = save_results_to_file(query_input, basic_summary)
                            st.markdown(f"\n\n*Results saved to {filename}*")
                else:
                    # Display detailed results
                    output = []
                    for i, doc in enumerate(search_results):
                        output.append(f"## Result {i+1}:\n\n{doc.page_content}\n\n---")
                    
                    display_content = "\n".join(output)
                    
                    # Save to file if requested
                    if save_checkbox:
                        detailed_content = f"Search query: {query_input}\n\n"
                        for i, doc in enumerate(search_results):
                            detailed_content += f"Result {i+1}:\n"
                            detailed_content += f"{doc.page_content}\n"
                            detailed_content += "-" * 50 + "\n\n"
                        
                        filename = save_results_to_file(query_input, detailed_content)
                        display_content += f"\n\n*Results saved to {filename}*"
                    
                    st.markdown(display_content)

# Display some information about the app
with st.expander("About this app"):
    st.markdown(f"""
    This app searches through the Roadfood database to find restaurants matching your criteria.
    It uses vector embeddings to find the most relevant matches to your query.
    
    The database contains restaurants from the Roadfood guide {EDITION} edition.
    
    When generating a summary article, the app uses OpenAI's language model to create two different summaries:
    
    1. **Basic Summary**: A concise overview with a list of restaurants and key highlights.
    2. **Advanced Summary**: A more detailed article with additional context and information.
    
    Both summaries include restaurant names, locations, and highlight what makes them special.
    """)

# Run the app
# Note: No need for if __name__ == "__main__" in Streamlit
# Streamlit apps are run with the command: streamlit run roadfood_search_app.py