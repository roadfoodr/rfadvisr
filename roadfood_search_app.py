import streamlit as st

import os
import yaml
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
import datetime
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import Document
import re

# Constants
EDITION = '10th'

# Set up Streamlit page configuration - MUST be the first Streamlit command
st.set_page_config(
    page_title=f"Roadfood {EDITION} Edition Search",
    page_icon="üçΩÔ∏è",
    layout="wide"
)

# OPENAI API SETUP
os.environ['OPENAI_API_KEY'] = yaml.safe_load(open('credentials.yml'))['openai']
MODEL_EMBEDDING = 'text-embedding-ada-002'
LLM_MODEL = 'gpt-3.5-turbo'
# LLM_MODEL = 'gpt-4o-mini'
FINE_TUNED_MODEL = 'ft:gpt-3.5-turbo-0125:personal:roadfood-10th:BAhLsi24'  # Replace with your actual fine-tuned model ID

# Initialize embedding function
@st.cache_resource
def get_embedding_function():
    return OpenAIEmbeddings(
        model=MODEL_EMBEDDING,
        
    )

# Initialize LLM
@st.cache_resource
def get_llm(use_fine_tuned=False):
    """Get the appropriate LLM model based on the selection
    
    Args:
        use_fine_tuned: Whether to use the fine-tuned model
        
    Returns:
        The appropriate LLM instance
    """
    if use_fine_tuned:
        return ChatOpenAI(model=FINE_TUNED_MODEL, temperature=0.7)
    else:
        return ChatOpenAI(model=LLM_MODEL, temperature=0.7)

# Load the existing Chroma database
@st.cache_resource
def get_vectorstore():
    embedding_function = get_embedding_function()
    persist_directory = f"./data/chroma_rf{EDITION}"
    return Chroma(
        embedding_function=embedding_function,
        persist_directory=persist_directory
    )

# Get cached resources
embedding_function = get_embedding_function()
llm = get_llm(use_fine_tuned=False)  # Default to base model
vectorstore = get_vectorstore()

def post_process_summary(summary_text, search_results):
    """
    Post-process the summary to bold all restaurant names and add hyperlinks to their first occurrence.
    
    Args:
        summary_text: The text of the summary generated by the LLM
        search_results: The search results containing restaurant metadata
    
    Returns:
        Processed summary text with formatting applied
    """
    # Extract restaurant names and URLs from search results
    restaurants = []
    for doc in search_results:
        # Extract metadata if available
        metadata = getattr(doc, 'metadata', {})
        restaurant_name = metadata.get('Restaurant', '')
        url = metadata.get('URL', '')
        
        # Only process if we have a restaurant name
        if restaurant_name:
            restaurants.append({
                'name': restaurant_name,
                'url': url
            })
    
    # Track first occurrences
    first_occurrence = {r['name']: True for r in restaurants}
    
    # Sort restaurant names by length (descending) to avoid partial replacements
    # (e.g., replace "Joe's Diner" before "Joe")
    restaurants.sort(key=lambda x: len(x['name']), reverse=True)
    
    # Process each restaurant name
    for restaurant in restaurants:
        name = restaurant['name']
        url = restaurant['url']
        
        # Skip empty names
        if not name.strip():
            continue
        
        # Create regex pattern to match whole words/phrases only
        # This avoids replacing parts of other words
        # Use word boundaries \b for single-word restaurant names
        if len(name.split()) == 1:
            # For single words, use word boundaries
            pattern = r'(?<!\*\*)\b' + re.escape(name) + r'\b(?!\*\*)'
        else:
            # For phrases, use the existing pattern
            pattern = r'(?<!\*\*)' + re.escape(name) + r'(?!\*\*)'
        
        # Check if the name appears in the text
        if re.search(pattern, summary_text, re.IGNORECASE):
            # For the first occurrence, add hyperlink (if URL exists) and bold
            if first_occurrence[name]:
                if url:
                    # Add https:// prefix if missing
                    if not url.startswith('http'):
                        url = f"https://{url}"
                    # Replace with hyperlinked and bolded version
                    replacement = f"[**{name}**]({url})"
                else:
                    # Just bold if no URL
                    replacement = f"**{name}**"
                
                # Replace only the first occurrence (case insensitive)
                summary_text = re.sub(pattern, replacement, summary_text, count=1, flags=re.IGNORECASE)
                first_occurrence[name] = False
                
                # Bold all subsequent occurrences
                # Use the same pattern for consistency
                summary_text = re.sub(pattern, f"**{name}**", summary_text, flags=re.IGNORECASE)
            
    return summary_text

def standardize_summary_headline(summary_text):
    """
    Standardize headline formatting in summaries to ensure consistent heading levels.
    
    This function:
    1. Identifies the title (content before the bullet list)
    2. Converts the title to an h3 header, removing any formatting or prefixes
    3. Leaves the rest of the content unchanged
    
    Args:
        summary_text: The text of the summary to process
        
    Returns:
        Processed summary text with standardized headings
    """
    # Split the text into lines for processing
    lines = summary_text.split('\n')
    
    # Skip any empty lines at the beginning
    start_index = 0
    while start_index < len(lines) and not lines[start_index].strip():
        start_index += 1
    
    # If we've reached the end, return the original text
    if start_index >= len(lines):
        return summary_text
    
    # Find the first bullet point or empty line after non-empty content
    bullet_index = -1
    for i in range(start_index + 1, len(lines)):
        line = lines[i].strip()
        # If this is a bullet point, we've found our separator
        if line.startswith('*') or line.startswith('-'):
            bullet_index = i
            break
        # If this is an empty line after we've seen content, it might be our separator
        if not line and i > start_index:
            # Check if the next line exists and is not empty (to avoid treating paragraph breaks as separators)
            if i + 1 < len(lines) and lines[i + 1].strip():
                bullet_index = i
                break
    
    # If we didn't find a bullet point or suitable empty line, just use the first line as the title
    if bullet_index == -1:
        # Extract and clean the first non-empty line as the title
        title = lines[start_index].strip()
        # Remove any markdown headers
        title = re.sub(r'^#+\s+', '', title)
        # Remove bold markers
        title = re.sub(r'\*\*', '', title)
        # Remove common title prefixes
        title = re.sub(r'^(?:Title:|Catchy Title:|Headline:)\s*', '', title, flags=re.IGNORECASE)
        
        # Replace the first line with the cleaned h3 title
        if title:  # Only if we have actual content
            lines[start_index] = f"### {title}"
        
        # Convert any other h1 or h2 headers to h3
        for i in range(start_index + 1, len(lines)):
            if lines[i].strip().startswith('# ') or lines[i].strip().startswith('## '):
                lines[i] = re.sub(r'^#+\s+', '### ', lines[i])
        
        return '\n'.join(lines)
    
    # We found a separator, so extract everything before it as the title
    title_lines = [line for line in lines[start_index:bullet_index] if line.strip()]
    
    # If we have title lines, process them
    if title_lines:
        # Join all title lines into a single string
        title_text = ' '.join([line.strip() for line in title_lines])
        
        # Clean up the title
        # Remove any markdown headers
        title_text = re.sub(r'^#+\s+', '', title_text)
        # Remove bold markers
        title_text = re.sub(r'\*\*', '', title_text)
        # Remove common title prefixes
        title_text = re.sub(r'^(?:Title:|Catchy Title:|Headline:)\s*', '', title_text, flags=re.IGNORECASE)
        
        # Create the new title as an h3 header
        new_title = f"### {title_text.strip()}"
        
        # Build the new content with the standardized title
        result = [new_title, '']  # Title followed by blank line
        result.extend(lines[bullet_index:])  # Add the rest unchanged
        
        return '\n'.join(result)
    
    # If we didn't find any title content, return the original text
    return summary_text

def load_prompt_template(prompt_type="basic"):
    """Load the prompt template from file
    
    Args:
        prompt_type: Type of prompt to load ("basic" or "advanced")
    
    Returns:
        The prompt template text or None if there was an error
    """
    filename = f"prompts/{prompt_type}_summary_prompt.txt"
    try:
        with open(filename, "r") as f:
            return f.read()
    except Exception as e:
        st.error(f"Error reading prompt template {filename}: {str(e)}")
        return None

def reload_prompt_template():
    """Clear the cache to reload the prompt template"""
    # Clear the cache to force reload of prompt
    st.cache_data.clear()
    st.success("Prompt templates reloaded!")

def generate_summary(query, full_content, search_results, prompt_type="basic", use_fine_tuned=False):
    """Generate a summary article from the search results using an LLM
    
    Args:
        query: The search query
        full_content: The full content of the search results
        search_results: The search results objects
        prompt_type: Type of prompt to use ("basic" or "advanced")
        use_fine_tuned: Whether to use the fine-tuned model
        
    Returns:
        The generated summary
    """
    # Read the prompt template from file
    prompt_text = load_prompt_template(prompt_type)
    
    # Fallback to hardcoded prompt if file can't be read
    if not prompt_text:
        prompt_text = """
        You are a food writer creating a summary article based on search results for "{query}".
        
        Here are the details of restaurants found in the search:
        {full_content}
                
        Format your response with markdown.
        """
    
    # Create the prompt for the LLM
    prompt_template = ChatPromptTemplate.from_template(prompt_text)
    
    # Get the appropriate model
    model = get_llm(use_fine_tuned=use_fine_tuned)
    
    # Generate the summary
    chain = prompt_template | model
    response = chain.invoke({"query": query, "full_content": full_content})
    
    # Post-process the summary to format restaurant names
    processed_summary = post_process_summary(response.content, search_results)
    
    return processed_summary

@st.cache_data
def perform_search(query, num_results):
    """Perform the vector search and return results"""
    if not query.strip():
        return []
    
    try:
        results = vectorstore.similarity_search(
            query=query,
            k=num_results
        )
        return results
    except Exception as e:
        st.error(f"Error during search: {str(e)}")
        return []

def prepare_download_content(query, content):
    """Prepare content for download without saving to disk"""
    # Format the content for download
    formatted_content = f"Search query: {query}\n\n{content}"
    return formatted_content

def prepare_download_content_for_summaries(query, summary_type, summaries):
    """Prepare content for download based on the selected summary type
    
    Args:
        query: The search query
        summary_type: The type of summary selected
        summaries: Dictionary containing all summary types
        
    Returns:
        Formatted content for download
    """
    content = f"Search query: {query}\n\n"
    
    if summary_type == "All":
        content += "BASIC SUMMARY (BASE MODEL):\n\n"
        content += summaries["basic_base"]
        content += "\n\n" + "="*50 + "\n\n"
        
        content += "ADVANCED SUMMARY (BASE MODEL):\n\n"
        content += summaries["advanced_base"]
        content += "\n\n" + "="*50 + "\n\n"
        
        content += "BASIC SUMMARY (FINE-TUNED MODEL):\n\n"
        content += summaries["basic_fine_tuned"]
        content += "\n\n" + "="*50 + "\n\n"
        
        content += "ADVANCED SUMMARY (FINE-TUNED MODEL):\n\n"
        content += summaries["advanced_fine_tuned"]
        
    elif summary_type == "Basic prompt / base model":
        content += summaries["basic_base"]
        
    elif summary_type == "Advanced prompt / base model":
        content += summaries["advanced_base"]
        
    elif summary_type == "Basic prompt / fine-tuned model":
        content += summaries["basic_fine_tuned"]
        
    elif summary_type == "Advanced prompt / fine-tuned model":
        content += summaries["advanced_fine_tuned"]
        
    return content

def generate_all_summary_types(query, full_content, search_results):
    """Generate all four types of summaries
    
    Args:
        query: The search query
        full_content: The full content of the search results
        search_results: The search results objects
        
    Returns:
        Dictionary containing all four summary types
    """
    summaries = {}
    
    # Generate basic summary with base model
    with st.spinner("Generating basic summary with base model..."):
        summaries["basic_base"] = generate_summary(
            query, full_content, search_results, 
            prompt_type="basic", use_fine_tuned=False
        )
    
    # Generate advanced summary with base model
    with st.spinner("Generating advanced summary with base model..."):
        summaries["advanced_base"] = generate_summary(
            query, full_content, search_results, 
            prompt_type="advanced", use_fine_tuned=False
        )
    
    # Generate basic summary with fine-tuned model
    with st.spinner("Generating basic summary with fine-tuned model..."):
        summaries["basic_fine_tuned"] = generate_summary(
            query, full_content, search_results, 
            prompt_type="basic", use_fine_tuned=True
        )
    
    # Generate advanced summary with fine-tuned model
    with st.spinner("Generating advanced summary with fine-tuned model..."):
        summaries["advanced_fine_tuned"] = generate_summary(
            query, full_content, search_results, 
            prompt_type="advanced", use_fine_tuned=True
        )
    
    return summaries

def display_summaries(summary_type, summaries):
    """Display summaries based on the selected type
    
    Args:
        summary_type: The type of summary to display
        summaries: Dictionary containing all summary types
    """
    if summary_type == "All":
        # Display all four summaries
        st.header("Basic Summary (Base Model)")
        st.markdown(standardize_summary_headline(summaries["basic_base"]))
        
        st.header("Advanced Summary (Base Model)")
        st.markdown(standardize_summary_headline(summaries["advanced_base"]))
        
        st.header("Basic Summary (Fine-tuned Model)")
        st.markdown(standardize_summary_headline(summaries["basic_fine_tuned"]))
        
        st.header("Advanced Summary (Fine-tuned Model)")
        st.markdown(standardize_summary_headline(summaries["advanced_fine_tuned"]))
        
    elif summary_type == "Basic prompt / base model":
        st.markdown(standardize_summary_headline(summaries["basic_base"]))
        
    elif summary_type == "Advanced prompt / base model":
        st.markdown(standardize_summary_headline(summaries["advanced_base"]))
        
    elif summary_type == "Basic prompt / fine-tuned model":
        st.markdown(standardize_summary_headline(summaries["basic_fine_tuned"]))
        
    elif summary_type == "Advanced prompt / fine-tuned model":
        st.markdown(standardize_summary_headline(summaries["advanced_fine_tuned"]))

# Create Streamlit interface
st.title(f"Roadfood {EDITION} Edition Restaurant Search")
st.markdown("Search for restaurants based on your preferences, cuisine, location, etc.")

# Example queries outside the form (these don't trigger re-renders)
example_queries = [
    "Where is the best BBQ?",
    "Unique seafood restaurants on the East Coast",
    "Famous diners in New Jersey",
    "Where can I find good pie?",
    "Historic restaurants with great burgers"
]

# Store the selected example in session state so we can use it in the form
if 'selected_example' not in st.session_state:
    st.session_state.selected_example = ""

def update_example():
    if st.session_state.example_selector:
        st.session_state.selected_example = st.session_state.example_selector

# Example selector outside the form
st.sidebar.header("Example Searches")
st.sidebar.selectbox(
    "Try an example search:",
    [""] + example_queries,
    key="example_selector",
    on_change=update_example
)

# Create a form for all search inputs
with st.sidebar:
    with st.form(key="search_form"):
        st.header("Search Options")
        
        # Search parameters
        query_input = st.text_area(
            "What are you looking for?",
            value=st.session_state.selected_example,
            placeholder="e.g., 'best BBQ in Texas' or 'unique seafood restaurants'"
        )
        
        num_results = st.slider(
            "Number of results",
            min_value=1,
            max_value=10,
            value=4,
            step=1
        )
        
        generate_article_checkbox = st.checkbox("Generate summary article", value=True)
        
        # Only show this option if generate_article_checkbox is checked
        summary_type = "All"
        if generate_article_checkbox:
            summary_type = st.selectbox(
                "Summary type",
                [
                    "All",
                    "Basic prompt / base model",
                    "Advanced prompt / base model",
                    "Basic prompt / fine-tuned model",
                    "Advanced prompt / fine-tuned model"
                ],
                index=0  # Default to "All"
            )
        
        save_checkbox = st.checkbox("Enable download option", value=False)
        
        # Form submit button
        search_submitted = st.form_submit_button("Search")

# Main content area - only process when form is submitted
if search_submitted:
    if not query_input.strip():
        st.warning("Please enter a search query.")
    else:
        with st.spinner("Searching for restaurants..."):
            # Perform the search
            search_results = perform_search(query_input, num_results)
            
            if search_results:
                # Process and display results based on user preferences
                if generate_article_checkbox:
                    # Extract full content for summarization
                    full_content = "\n\n".join([doc.page_content for doc in search_results])
                    
                    # Generate summaries based on the selected type
                    if summary_type == "All":
                        # Generate all summary types
                        summaries = generate_all_summary_types(query_input, full_content, search_results)
                        
                        # Display all summaries
                        display_summaries(summary_type, summaries)
                        
                        # Save all summaries if requested
                        if save_checkbox:
                            download_content = prepare_download_content_for_summaries(query_input, summary_type, summaries)
                            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                            filename = f"search_results_{timestamp}.txt"
                            st.download_button(
                                label="Download Results",
                                data=download_content,
                                file_name=filename,
                                mime="text/plain"
                            )
                    elif summary_type == "Basic prompt / base model":
                        # Generate basic summary with base model
                        with st.spinner("Generating basic summary with base model..."):
                            basic_base = generate_summary(query_input, full_content, search_results, 
                                                         prompt_type="basic", use_fine_tuned=False)
                            summaries = {"basic_base": basic_base}
                            
                            # Display the summary
                            display_summaries(summary_type, summaries)
                            
                            # Save if requested
                            if save_checkbox:
                                download_content = prepare_download_content_for_summaries(query_input, summary_type, summaries)
                                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"search_results_{timestamp}.txt"
                                st.download_button(
                                    label="Download Results",
                                    data=download_content,
                                    file_name=filename,
                                    mime="text/plain"
                                )
                    elif summary_type == "Advanced prompt / base model":
                        # Generate advanced summary with base model
                        with st.spinner("Generating advanced summary with base model..."):
                            advanced_base = generate_summary(query_input, full_content, search_results, 
                                                           prompt_type="advanced", use_fine_tuned=False)
                            summaries = {"advanced_base": advanced_base}
                            
                            # Display the summary
                            display_summaries(summary_type, summaries)
                            
                            # Save if requested
                            if save_checkbox:
                                download_content = prepare_download_content_for_summaries(query_input, summary_type, summaries)
                                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"search_results_{timestamp}.txt"
                                st.download_button(
                                    label="Download Results",
                                    data=download_content,
                                    file_name=filename,
                                    mime="text/plain"
                                )
                    elif summary_type == "Basic prompt / fine-tuned model":
                        # Generate basic summary with fine-tuned model
                        with st.spinner("Generating basic summary with fine-tuned model..."):
                            basic_fine_tuned = generate_summary(query_input, full_content, search_results, 
                                                              prompt_type="basic", use_fine_tuned=True)
                            summaries = {"basic_fine_tuned": basic_fine_tuned}
                            
                            # Display the summary
                            display_summaries(summary_type, summaries)
                            
                            # Save if requested
                            if save_checkbox:
                                download_content = prepare_download_content_for_summaries(query_input, summary_type, summaries)
                                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"search_results_{timestamp}.txt"
                                st.download_button(
                                    label="Download Results",
                                    data=download_content,
                                    file_name=filename,
                                    mime="text/plain"
                                )
                    elif summary_type == "Advanced prompt / fine-tuned model":
                        # Generate advanced summary with fine-tuned model
                        with st.spinner("Generating advanced summary with fine-tuned model..."):
                            advanced_fine_tuned = generate_summary(query_input, full_content, search_results, 
                                                                 prompt_type="advanced", use_fine_tuned=True)
                            summaries = {"advanced_fine_tuned": advanced_fine_tuned}
                            
                            # Display the summary
                            display_summaries(summary_type, summaries)
                            
                            # Save if requested
                            if save_checkbox:
                                download_content = prepare_download_content_for_summaries(query_input, summary_type, summaries)
                                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                                filename = f"search_results_{timestamp}.txt"
                                st.download_button(
                                    label="Download Results",
                                    data=download_content,
                                    file_name=filename,
                                    mime="text/plain"
                                )
                else:
                    # Display detailed results
                    output = []
                    for i, doc in enumerate(search_results):
                        output.append(f"## Result {i+1}:\n\n{doc.page_content}\n\n---")
                    
                    display_content = "\n".join(output)
                    
                    # Save to file if requested
                    if save_checkbox:
                        detailed_content = f"Search query: {query_input}\n\n"
                        for i, doc in enumerate(search_results):
                            detailed_content += f"Result {i+1}:\n"
                            detailed_content += f"{doc.page_content}\n"
                            detailed_content += "-" * 50 + "\n\n"
                        
                        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"search_results_{timestamp}.txt"
                        st.download_button(
                            label="Download Results",
                            data=detailed_content,
                            file_name=filename,
                            mime="text/plain"
                        )
                    
                    st.markdown(display_content)

# Display some information about the app
with st.expander("About this app"):
    st.markdown(f"""
    This app searches through the Roadfood database to find restaurants matching your criteria.
    It uses vector embeddings to find the most relevant matches to your query.
    
    The database contains restaurants from the Roadfood guide {EDITION} edition.
    
    When generating a summary article, the app offers several options:
    
    1. **Basic prompt / base model**: A concise overview using a simpler prompt with the standard model.
    2. **Advanced prompt / base model**: A more detailed article using a comprehensive prompt with the standard model.
    3. **Basic prompt / fine-tuned model**: A concise overview using a simpler prompt with a model fine-tuned specifically for Roadfood summaries.
    4. **Advanced prompt / fine-tuned model**: A more detailed article using a comprehensive prompt with the fine-tuned model.
    5. **All**: Generates all four summary types for comparison.
    
    All summaries include restaurant names, locations, and highlight what makes them special.
    """)

# Add developer options in a collapsed expander at the bottom of the sidebar
with st.sidebar:
    with st.expander("Developer Options", expanded=False):
        if st.button("Reload Prompt Template"):
            reload_prompt_template()

# Run the app
# Note: No need for if __name__ == "__main__" in Streamlit
# Streamlit apps are run with the command: streamlit run roadfood_search_app.py